{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98df812-5542-4f3f-ba0c-5502b7914aa9",
   "metadata": {},
   "source": [
    "Codificação de variáveis textuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749be62-841e-45a4-909e-726ac145bcc1",
   "metadata": {},
   "source": [
    "## 1) *Explicação:* informações sobre o motivo de codificar variáveis textuais e falar dois dos tipos de codificação mais conhecidos: **Bag-of-words e tf-idf.** \n",
    "\n",
    "\n",
    "##  *Porque codificar variaveis textuais?* \n",
    "#### O principal motivo é que a maioria dos algoritmos de Machine Learning trabalham com features/variaveis, e a maioria das váriaves categoricas são do tipo texto(string) e por isso é importante essa conversão.\n",
    "\n",
    "## *Compreendendo o contexto de aplicação de codificação em variaveis textuais*\n",
    "#### Cada palavra (termo) que aparece no documento faz parte de um vetor que em sua totalidade representa um documento.A seleção de características de texto é uma maneira eficaz para reduzir a dimensão do modelo de espaço vetorial, onde o objetivo é selecionar um subconjunto reduzido, porém com forte capacidade de representação do conjunto de palavras originais.\n",
    "\n",
    "## *Bag of Words BoW*\n",
    "#### É uma forma de representar o texto de acordo com a ocorrência das palavras nele. Traduzindo para o português, o “saco de palavras” recebe esse nome porque não leva em conta a ordem ou a estrutura das palavras no texto, apenas se ela aparece ou a frequência com que aparece nele.\n",
    "\n",
    "## *TF-IDF* \n",
    "##### Trata-se de medidas estatísticas para medir o quão importante uma palavra é em um documento (texto), assim como BoW, mas com algumas diferenças."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3b577-89f3-401c-b13a-195a2bf3ec05",
   "metadata": {},
   "source": [
    "#### A prática a seguir, foi realizada utilizando o tutorial encontrando como base o seguinte artigo : https://medium.com/turing-talks/introdu%C3%A7%C3%A3o-a-bag-of-words-e-tf-idf-43a128151ce9 que foi utilizada para estudos e compreensão do processo que estavam sendo desenvolvidos, alguns conhecimentos de python foram revisados e outros precisariam de um pouco mais de aprofundamento da minha parte para aperfeiçoa-los, o que foi devidamente anotado para dúvidas posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c2b5e-a71c-40e4-8060-d501758acb80",
   "metadata": {},
   "source": [
    "## Prática 1: criar células de código mostrando na prática como deve ser feita a codificação usando bag-of-words e tf-idf. Crie exemplos usando a seguinte lista de frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2161daf9-0497-466e-91ec-0a66c673689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleção do conjunto de dados:\n",
    "\n",
    "frases =[ \"John likes\",\n",
    "    \"likes to\",\n",
    "    \"to watch\",\n",
    "    \"watch movies\",\n",
    "    \"Mary likes\",\n",
    "    \"likes movies\",\n",
    "    \"movies too\",\n",
    "        ]\n",
    "\n",
    "# transformei as listas em string para poder manipular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d841d99-0fec-4a24-af61-0e4fba3f5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John likes,likes to,to watch,watch movies,Mary likes,likes movies,movies too\n"
     ]
    }
   ],
   "source": [
    "frases1 = \",\".join(frases)\n",
    "print(frases1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d117c5-8efb-4d49-b857-cef6ce89d253",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "### preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c010556-ca80-4aa9-9bfb-f3dce17fe981",
   "metadata": {
    "tags": []
   },
   "source": [
    "## inicio da pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9933b750-6075-41da-affa-0ad0a1bf4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#deixa todas as letras minúsculas\n",
    "texto_min = frases1.lower()\n",
    "\n",
    "#seleciona apenas letras (lembrando que o texto está em português e as letras possuem acento)\n",
    "apenas_letras = re.findall(r'[a-zéóáêâãõç]+', texto_min)\n",
    "\n",
    "#junta o texto, já que o .findall separa em tokens\n",
    "novo_texto = \" \".join(apenas_letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6427ea4b-eb2b-4501-b8d4-84c78c76b04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john likes likes to to watch watch movies mary likes likes movies movies too'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a3f04-b56a-4b7b-8db9-c4dff81524f0",
   "metadata": {},
   "source": [
    "### Gerando vocabulário\n",
    "\n",
    "## o vocabulário que nada mais é que a coleção de todas as palavras que ocorrem em um texto, basta passarmos todas elas uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb25ab0-6dcd-4f36-8831-680067c0b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/damas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadc1170-a299-4009-b525-9a068501d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john',\n",
       " 'likes',\n",
       " 'likes',\n",
       " 'to',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'watch',\n",
       " 'movies',\n",
       " 'mary',\n",
       " 'likes',\n",
       " 'likes',\n",
       " 'movies',\n",
       " 'movies',\n",
       " 'too']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(novo_texto)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7821d-67f3-4f71-8d19-a922f7e277f5",
   "metadata": {},
   "source": [
    "### Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d6a045-a13d-4c9f-bd22-f92bf0191f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john', 'likes', 'to', 'watch', 'movies', 'mary', 'too'] \n",
      " 7\n"
     ]
    }
   ],
   "source": [
    "Vocab = []\n",
    "for token in tokens:\n",
    "    if token not in Vocab:\n",
    "        Vocab.append(token)\n",
    "\n",
    "print(Vocab,\"\\n\",len(Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2009827-f0f9-44fa-a7c6-e68e851d9fb5",
   "metadata": {},
   "source": [
    "### Formando Vetor do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60720aed-c8b7-41ed-bcc6-e6cb87891487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81266e9-2cf1-4470-abdc-6c7a0c148b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_vetor_documento(documento, vocab):\n",
    "  vetor = []\n",
    "\n",
    "  for palavra in vocab:\n",
    "    if palavra in documento:\n",
    "        vetor.append(1)\n",
    "    else:\n",
    "        vetor.append(0)\n",
    "  \n",
    "  return np.array(vetor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27cf37-d845-4fa4-a033-9e44a925f3ca",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf20548-8a09-4983-aa7f-21b7798f8731",
   "metadata": {},
   "source": [
    "#### Trata-se de medidas estatísticas para medir o quão importante uma palavra é em um documento (texto), assim como BoW, mas com algumas diferenças. Com ele, podemos perceber a importância de uma palavra por meio de uma pontuação, o TF-IDF de uma palavra em um texto é feito multiplicando duas métricas diferentes:\n",
    "\n",
    "#### term Frequency (a frequência do termo), que mede a frequência com que um termo ocorre num documento;\n",
    "#### Inverse Document Frequency (inverso da frequência nos documentos), que mede o quão importante um termo é no contexto de todos os documentos.\n",
    "#### quanto mais frequente uma palavra é em seu documento, mais importante ela tende a ser. Entretanto, isso depende da repetição dela ao longo de todos os documentos que estão sendo analisados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794c39c-b840-411a-9ca6-990b2890a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar um dicionário de frequência dos termos\n",
    "# Para criar o dicionário vamos criar uma função dicionario_de_contagem, que retorna a palavra e a quantidade de ocorrências dela.\n",
    "#basicamente, essa função recebe como argumento a lista Vocab,\n",
    "#que já criamos, e o documento tokenizado, e cria um dicionário com as palavras do poema seguidas do número de ocorrências delas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75c105fd-11e0-4fe4-b423-4bf369f7b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases2 =[ \"John likes\",\n",
    "    \"likes to\",\n",
    "    \"to watch\",\n",
    "    \"watch movies\",\n",
    "    \"Mary likes\",\n",
    "    \"likes movies\",\n",
    "    \"movies too\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba2b49e3-ae62-45b9-a3af-3eccf82f2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John likes,likes to,to watch,watch movies,Mary likes,likes movies,movies too\n"
     ]
    }
   ],
   "source": [
    "frases2_ = \",\".join(frases)\n",
    "print(frases2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871a0e8f-c0d2-4a23-8928-b2ae46bd506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john likes', 'likes to', 'to watch', 'watch movies', 'mary likes', 'likes movies', 'movies too']\n"
     ]
    }
   ],
   "source": [
    "#deixa todas as letras minúsculas \n",
    "out = map(lambda x:x.lower(), [ \"John likes\", \"likes to\",\"to watch\", \"watch movies\", \"Mary likes\", \"likes movies\",\"movies too\",]) \n",
    "output = list(out) \n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eee8905-e496-4bda-a18a-9f03f5894c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john likes,likes to,to watch,watch movies,mary likes,likes movies,movies too\n"
     ]
    }
   ],
   "source": [
    "frases_2 = \",\".join(output)\n",
    "print(frases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfddeb38-87cf-4096-b2a3-39480f7e3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"\"\"john likes\"\"\"\n",
    "\n",
    "doc2=  \"\"\"likes to\"\"\"\n",
    "\n",
    "doc3 = \"\"\"to watch\"\"\"\n",
    "\n",
    "doc4= \"\"\"watch movies\"\"\"\n",
    "\n",
    "doc5= \"\"\"mary likes\"\"\"\n",
    "\n",
    "doc6= \"\"\"likes movies\"\"\"\n",
    "\n",
    "doc7= \"\"\"movies too\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d7bdf32-7150-4699-8c8e-79cf5697cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_tokens = doc1.split()\n",
    "\n",
    "e2_tokens = doc2.split()\n",
    "\n",
    "e3_tokens = doc3.split()\n",
    "\n",
    "e4_tokens = doc4.split()\n",
    "\n",
    "e5_tokens = doc5.split()\n",
    "\n",
    "e6_tokens = doc6.split()\n",
    "\n",
    "e7_tokens = doc7.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b0458aa-b557-40c4-a165-9e052c4640e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicionario_de_contagem(vocabulario, documento):\n",
    "  '''Recebe uma lista com o vocabulario e uma lista de tokens de um documento.\n",
    "  Retorna um dicionario com o numero de vezes que cada palavra do vocabulario\n",
    "  ocorre no documento.'''\n",
    "  dic = dict.fromkeys(vocabulario, 1)\n",
    "  for palavra in documento:\n",
    "    dic[palavra] += 1\n",
    "  return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9c12ba-2458-4d6c-8b13-9e096183a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'john': 2, 'likes': 2, 'to': 1, 'watch': 1, 'movies': 1, 'mary': 1, 'too': 1} \n",
      "\n",
      "{'john': 1, 'likes': 2, 'to': 2, 'watch': 1, 'movies': 1, 'mary': 1, 'too': 1}\n",
      "{'john': 1, 'likes': 1, 'to': 2, 'watch': 2, 'movies': 1, 'mary': 1, 'too': 1}\n",
      "{'john': 1, 'likes': 1, 'to': 1, 'watch': 2, 'movies': 2, 'mary': 1, 'too': 1}\n",
      "{'john': 1, 'likes': 2, 'to': 1, 'watch': 1, 'movies': 1, 'mary': 2, 'too': 1}\n",
      "{'john': 1, 'likes': 2, 'to': 1, 'watch': 1, 'movies': 2, 'mary': 1, 'too': 1}\n",
      "{'john': 1, 'likes': 1, 'to': 1, 'watch': 1, 'movies': 2, 'mary': 1, 'too': 2}\n"
     ]
    }
   ],
   "source": [
    "e1_dic_cont = dicionario_de_contagem(Vocab, e1_tokens)\n",
    "e2_dic_cont = dicionario_de_contagem(Vocab, e2_tokens)\n",
    "e3_dic_cont = dicionario_de_contagem(Vocab, e3_tokens)\n",
    "e4_dic_cont = dicionario_de_contagem(Vocab, e4_tokens)\n",
    "e5_dic_cont = dicionario_de_contagem(Vocab, e5_tokens)\n",
    "e6_dic_cont = dicionario_de_contagem(Vocab, e6_tokens)\n",
    "e7_dic_cont = dicionario_de_contagem(Vocab, e7_tokens)\n",
    "\n",
    "print(e1_dic_cont,'\\n')\n",
    "print(e2_dic_cont)\n",
    "print(e3_dic_cont)\n",
    "print(e4_dic_cont)\n",
    "print(e5_dic_cont)\n",
    "print(e6_dic_cont)\n",
    "print(e7_dic_cont)\n",
    "\n",
    "\n",
    "#aqui notei 2 erros, que resolvi pq o banco de dados era pequeno, que era a questão das letras maicusulas e minusculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ff91b-d2e6-47f8-a140-250cebb2da87",
   "metadata": {},
   "source": [
    "# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8410632b-e4a1-4ee4-8d62-f0506450843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaTF(dic_de_cont, doc):     \n",
    "    tf_dic = {}\n",
    "    num_palavras_doc = len(doc)     \n",
    "    for palavra, contagem in dic_de_cont.items():         \n",
    "        tf_dic[palavra] = contagem/float(num_palavras_doc)     \n",
    "    return(tf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aefe077-92d7-4a48-a7ee-401e0f1620c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_tf_bow = calculaTF(e1_dic_cont, e1_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa5fa0a-7981-44c9-b4d2-0460ff905d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_tf_bow = calculaTF(e2_dic_cont, e2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa4bf65-141f-4a42-8f20-0ec415d4d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'john': 1.0, 'likes': 1.0, 'to': 0.5, 'watch': 0.5, 'movies': 0.5, 'mary': 0.5, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 1.0, 'to': 1.0, 'watch': 0.5, 'movies': 0.5, 'mary': 0.5, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 0.5, 'to': 1.0, 'watch': 1.0, 'movies': 0.5, 'mary': 0.5, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 0.5, 'to': 0.5, 'watch': 1.0, 'movies': 1.0, 'mary': 0.5, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 1.0, 'to': 0.5, 'watch': 0.5, 'movies': 0.5, 'mary': 1.0, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 1.0, 'to': 0.5, 'watch': 0.5, 'movies': 1.0, 'mary': 0.5, 'too': 0.5}\n",
      "{'john': 0.5, 'likes': 0.5, 'to': 0.5, 'watch': 0.5, 'movies': 1.0, 'mary': 0.5, 'too': 1.0}\n"
     ]
    }
   ],
   "source": [
    "e1_tf_bow = calculaTF(e1_dic_cont, e1_tokens)\n",
    "e2_tf_bow = calculaTF(e2_dic_cont, e2_tokens)\n",
    "e3_tf_bow = calculaTF(e3_dic_cont, e3_tokens)\n",
    "e4_tf_bow = calculaTF(e4_dic_cont, e4_tokens)\n",
    "e5_tf_bow = calculaTF(e5_dic_cont, e5_tokens)\n",
    "e6_tf_bow = calculaTF(e6_dic_cont, e6_tokens)\n",
    "e7_tf_bow = calculaTF(e7_dic_cont, e7_tokens)\n",
    "\n",
    "print(e1_tf_bow)\n",
    "print(e2_tf_bow)\n",
    "print(e3_tf_bow)\n",
    "print(e4_tf_bow)\n",
    "print(e5_tf_bow)\n",
    "print(e6_tf_bow)\n",
    "print(e7_tf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f4805f4-65f4-49ae-90da-759e0d9056d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 1.0,\n",
       " 'likes': 1.0,\n",
       " 'to': 0.5,\n",
       " 'watch': 0.5,\n",
       " 'movies': 0.5,\n",
       " 'mary': 0.5,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94ab0ac2-0f28-48a6-864d-48e55ad3f2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 1.0,\n",
       " 'to': 1.0,\n",
       " 'watch': 0.5,\n",
       " 'movies': 0.5,\n",
       " 'mary': 0.5,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e4a61f-eff7-4f7c-a120-806642404111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 0.5,\n",
       " 'to': 1.0,\n",
       " 'watch': 1.0,\n",
       " 'movies': 0.5,\n",
       " 'mary': 0.5,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e3_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be3fdb84-b921-46c8-8b0a-1cc0bc60b2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 0.5,\n",
       " 'to': 0.5,\n",
       " 'watch': 1.0,\n",
       " 'movies': 1.0,\n",
       " 'mary': 0.5,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e4_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236172ac-d03c-4386-a226-484b3ec893b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 1.0,\n",
       " 'to': 0.5,\n",
       " 'watch': 0.5,\n",
       " 'movies': 0.5,\n",
       " 'mary': 1.0,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e5_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28010804-a658-40b0-a494-c53207decf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 1.0,\n",
       " 'to': 0.5,\n",
       " 'watch': 0.5,\n",
       " 'movies': 1.0,\n",
       " 'mary': 0.5,\n",
       " 'too': 0.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e6_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d40ce0f-0770-4767-a718-a20e3d9163a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.5,\n",
       " 'likes': 0.5,\n",
       " 'to': 0.5,\n",
       " 'watch': 0.5,\n",
       " 'movies': 1.0,\n",
       " 'mary': 0.5,\n",
       " 'too': 1.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e7_tf_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f1ed2-7afc-4d9a-8885-871b66ef78b5",
   "metadata": {},
   "source": [
    "# idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d700c6e-76c5-4db0-8d97-d0c836020182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc97c12-1fd1-4aed-934f-a38f215bb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computaIDF(lista_de_docs):\n",
    "    idf_dic = {}\n",
    "    N = len(lista_de_docs)\n",
    "\n",
    "    for palavra in lista_de_docs[0]:\n",
    "        num_docs_aparece = 0\n",
    "        for doc in lista_de_docs:\n",
    "            if doc[palavra]>0:\n",
    "                num_docs_aparece += 1\n",
    "        \n",
    "        idf_dic[palavra] = math.log10(N / (num_docs_aparece))\n",
    "\n",
    "    return (idf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4022c08-da99-4ea3-a519-994947f8015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estrofes_idf = computaIDF([e1_dic_cont, e2_dic_cont, e2_dic_cont, e3_dic_cont, e4_dic_cont, e5_dic_cont,e5_dic_cont, e7_dic_cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ffde00c-edb1-4f69-9feb-1ca5107b8628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estrofes_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b34c5d-8f54-4561-8d1b-94a7d0393089",
   "metadata": {},
   "source": [
    "### Juntando TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9c12a68-af63-4032-b900-7e9371903fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computaTFIDF(tf_bow, idfs):\n",
    "    tfidf = {}\n",
    "\n",
    "    for palavra in tf_bow:\n",
    "        tf = tf_bow[palavra]\n",
    "        idf = idfs[palavra]\n",
    "        tfidf[palavra] = tf*idf\n",
    "        \n",
    "    return(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4bd0591-b001-4d2b-a5c1-c3f16cad3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_tfidf = computaTFIDF(e1_tf_bow, estrofes_idf)\n",
    "e2_tfidf = computaTFIDF(e2_tf_bow, estrofes_idf)\n",
    "e3_tfidf = computaTFIDF(e3_tf_bow, estrofes_idf)\n",
    "e4_tfidf = computaTFIDF(e4_tf_bow, estrofes_idf)\n",
    "e5_tfidf = computaTFIDF(e5_tf_bow, estrofes_idf)\n",
    "e6_tfidf = computaTFIDF(e6_tf_bow, estrofes_idf)\n",
    "e7_tfidf = computaTFIDF(e7_tf_bow, estrofes_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a5a564a-65db-4192-b245-16b7808edde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_tfidf # achei estranho estar dando 0 em todas as variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60af9280-825a-4b48-bb4c-85f103699506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ab1d854-8685-4f0e-8a47-541adc9cb2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e3_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4432b271-7eef-459a-9fd5-cd1a76836cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e4_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f47dbc5-8d88-4b73-9c82-feea5a82b1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e5_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8690c1f-43de-4e9d-bde1-1d34a1dd9d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e6_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98fb99ee-26e9-4fa1-a83e-1823878b9267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 0.0,\n",
       " 'likes': 0.0,\n",
       " 'to': 0.0,\n",
       " 'watch': 0.0,\n",
       " 'movies': 0.0,\n",
       " 'mary': 0.0,\n",
       " 'too': 0.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e7_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55970579-c926-4914-9dfc-6c0d8a95eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f867b010-524e-4f2d-b5c1-82c75ab787bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1172/1919510856.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tfidf_dataframe.drop('index', 1, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>to</th>\n",
       "      <th>watch</th>\n",
       "      <th>movies</th>\n",
       "      <th>mary</th>\n",
       "      <th>too</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      john  likes   to  watch  movies  mary  too\n",
       "doc1   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc2   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc3   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc4   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc5   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc6   0.0    0.0  0.0    0.0     0.0   0.0  0.0\n",
       "doc7   0.0    0.0  0.0    0.0     0.0   0.0  0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dataframe = pd.DataFrame([e1_tfidf, e2_tfidf,e3_tfidf,e4_tfidf,e5_tfidf,e6_tfidf,e7_tfidf])\n",
    "tfidf_dataframe[\"frases_2\"] = ['doc1', 'doc2','doc3','doc4','doc5','doc6','doc7']\n",
    "tfidf_dataframe.reset_index(inplace=True)\n",
    "tfidf_dataframe.drop('index', 1, inplace = True)\n",
    "tfidf_dataframe.set_index('frases_2', inplace=True)\n",
    "tfidf_dataframe.index.name = None\n",
    "\n",
    "tfidf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1663a9a-4c23-4207-89bc-6816fff8bcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
